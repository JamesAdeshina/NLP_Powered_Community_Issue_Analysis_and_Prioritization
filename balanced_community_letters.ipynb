{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the CSV file\n",
    "file_path = \"Data/raw/community_issues_dataset_long.csv\"\n",
    "data = pd.read_csv(file_path)"
   ],
   "id": "a9b4ceb27e183e0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop the 'Category' column\n",
    "data = data.drop(columns=['Category'])\n",
    "\n",
    "# Confirm that the column is dropped by displaying the first few rows\n",
    "print(data.head())\n"
   ],
   "id": "e312d13700ee8e32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# List of columns you want to check distributions for\n",
    "columns_to_check = ['Sentiment', 'Severity']\n",
    "\n",
    "# Loop through each column and check the distribution\n",
    "for column in columns_to_check:\n",
    "    # Print the distribution of the column\n",
    "    print(f\"Distribution for {column}:\")\n",
    "    print(data[column].value_counts())\n",
    "    print(\"\\n\" + \"-\"*40)  # Separator for readability\n",
    "\n",
    "    # Plot the distribution for each column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    data[column].value_counts().plot(kind='bar', color='skyblue')\n",
    "    plt.title(f'Distribution of {column} Values')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ],
   "id": "fd4c6345af4e7cf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Balance based on 'Severity'\n",
    "# Find the minimum count for each 'Severity' across different 'Sentiment' groups\n",
    "severity_group_sizes = data.groupby(['Severity', 'Sentiment']).size().unstack(fill_value=0)\n",
    "min_severity_count = severity_group_sizes.min().min()  # Minimum value across the severity group combinations\n",
    "\n",
    "# Create an empty list to store the subsets after balancing 'Severity'\n",
    "balanced_severity_data = []\n",
    "\n",
    "for severity, group in data.groupby('Severity'):\n",
    "    # For each severity level, balance the 'Sentiment' groups individually\n",
    "    sentiment_groups = group.groupby('Sentiment')\n",
    "    balanced_groups = []\n",
    "\n",
    "    # For each sentiment group within the current severity, sample to match the minimum count\n",
    "    for sentiment, sentiment_group in sentiment_groups:\n",
    "        sampled_group = sentiment_group.sample(min_severity_count, random_state=42) if len(sentiment_group) > min_severity_count else sentiment_group\n",
    "        balanced_groups.append(sampled_group)\n",
    "\n",
    "    # Concatenate the balanced sentiment groups for the current severity\n",
    "    balanced_severity_data.append(pd.concat(balanced_groups))\n",
    "\n",
    "# Concatenate all the severity-balanced data into one DataFrame\n",
    "balanced_severity_data = pd.concat(balanced_severity_data)\n",
    "\n",
    "# Step 2: Now balance based on 'Sentiment'\n",
    "# For each 'Sentiment', find the minimum count across the severity levels\n",
    "sentiment_group_sizes = balanced_severity_data.groupby(['Sentiment', 'Severity']).size().unstack(fill_value=0)\n",
    "min_sentiment_count = sentiment_group_sizes.min().min()  # Minimum value across sentiment group combinations\n",
    "\n",
    "# Create an empty list to store the subsets after balancing 'Sentiment'\n",
    "final_balanced_data = []\n",
    "\n",
    "for sentiment, group in balanced_severity_data.groupby('Sentiment'):\n",
    "    # For each sentiment level, balance the 'Severity' groups individually\n",
    "    severity_groups = group.groupby('Severity')\n",
    "    balanced_groups = []\n",
    "\n",
    "    # For each severity group within the current sentiment, sample to match the minimum count\n",
    "    for severity, severity_group in severity_groups:\n",
    "        sampled_group = severity_group.sample(min_sentiment_count, random_state=42) if len(severity_group) > min_sentiment_count else severity_group\n",
    "        balanced_groups.append(sampled_group)\n",
    "\n",
    "    # Concatenate the balanced severity groups for the current sentiment\n",
    "    final_balanced_data.append(pd.concat(balanced_groups))\n",
    "\n",
    "# Concatenate all the sentiment-balanced data into one DataFrame\n",
    "final_balanced_data = pd.concat(final_balanced_data)\n",
    "\n",
    "# Reset the index of the final DataFrame\n",
    "final_balanced_data = final_balanced_data.reset_index(drop=True)\n",
    "\n",
    "# Check the distribution in the resulting dataset\n",
    "print(final_balanced_data.groupby(['Sentiment', 'Severity']).size())\n",
    "\n",
    "# Optionally, visualize the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution for both 'Sentiment' and 'Severity'\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Sentiment distribution\n",
    "final_balanced_data['Sentiment'].value_counts().plot(kind='bar', ax=ax1, color=['skyblue', 'orange', 'green'])\n",
    "ax1.set_title('Sentiment Distribution')\n",
    "ax1.set_xlabel('Sentiment')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "# Severity distribution\n",
    "final_balanced_data['Severity'].value_counts().plot(kind='bar', ax=ax2, color=['skyblue', 'orange', 'green'])\n",
    "ax2.set_title('Severity Distribution')\n",
    "ax2.set_xlabel('Severity')\n",
    "ax2.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "30f783da4186c982",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(final_balanced_data.head())",
   "id": "fa51ae8d6f0234a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_balanced_data.drop_duplicates(subset=[\"Letter Text\"], inplace=True)\n",
   "id": "d1709ef81f2db45c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T04:43:44.122080Z",
     "start_time": "2025-02-21T04:43:43.506583Z"
    }
   },
   "cell_type": "code",
   "source": "final_balanced_data.drop(columns=[\"Issue Name\"], inplace=True)\n",
   "id": "45939ce93f53a7f",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Issue Name'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[87], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfinal_balanced_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mIssue Name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Work/Bolsover District Council/Project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdrop\u001B[39m(\n\u001B[1;32m   5434\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5435\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5442\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5443\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5444\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5445\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5446\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5579\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5583\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5587\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5588\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5589\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Work/Bolsover District Council/Project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4786\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4788\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4791\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/Documents/Work/Bolsover District Council/Project/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4830\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4828\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4829\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4830\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4831\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4833\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4834\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Work/Bolsover District Council/Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   7068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   7069\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 7070\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   7071\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   7072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['Issue Name'] not found in axis\""
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T04:43:34.073891Z",
     "start_time": "2025-02-21T04:43:34.029409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(final_balanced_data.isnull().sum())# Check missing data\n",
    "\n"
   ],
   "id": "999026e9bf4c0c2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity       0\n",
      "Frequency      0\n",
      "Sentiment      0\n",
      "Letter Text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "80c7c1ca9468396f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4eadcd7fb9914de9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a820b8642380c308",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
