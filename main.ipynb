{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setting Up the Environment",
   "id": "629ef4c65adadaf0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "!pip install pandas numpy scikit-learn spacy transformers flask fastapi matplotlib seaborn"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Ingestion",
   "id": "fa69f1fe02dc3413"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "# Function to load data from a folder of PDFs\n",
    "def load_data_from_folder(folder_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "            data.append({\"filename\": filename, \"text\": text})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load data\n",
    "data_folder = \"path/to/letters\"\n",
    "df = load_data_from_folder(data_folder)\n",
    "print(df.head())"
   ],
   "id": "88734e933c770b67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Text Preprocessing",
   "id": "44f87211fa8e9763"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text using spaCy\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"processed_text\"] = df[\"cleaned_text\"].apply(preprocess_text)\n",
    "print(df.head())"
   ],
   "id": "624c95d894266b4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Issue Categorization",
   "id": "3247ba16de17ea71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define issue categories (example)\n",
    "categories = [\"Air Pollution\", \"Traffic Congestion\", \"Potholes\", \"Noise Pollution\"]\n",
    "\n",
    "# Sample labeled data (replace with your own)\n",
    "labeled_data = [\n",
    "    {\"text\": \"The air quality in our area is terrible.\", \"category\": \"Air Pollution\"},\n",
    "    {\"text\": \"The traffic on Main Street is unbearable.\", \"category\": \"Traffic Congestion\"},\n",
    "    {\"text\": \"There are potholes everywhere on Elm Road.\", \"category\": \"Potholes\"},\n",
    "]\n",
    "\n",
    "# Convert labeled data to DataFrame\n",
    "labeled_df = pd.DataFrame(labeled_data)\n",
    "\n",
    "# Create a text classification pipeline\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(labeled_df[\"text\"], labeled_df[\"category\"])\n",
    "\n",
    "# Predict categories for new letters\n",
    "df[\"predicted_category\"] = model.predict(df[\"processed_text\"])\n",
    "print(df[[\"text\", \"predicted_category\"]].head())"
   ],
   "id": "9a78cc1fe6c9d51c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sentiment Analysis",
   "id": "dd9a357efe0d3b39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained sentiment analysis model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function to analyze sentiment\n",
    "def analyze_sentiment(text):\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    return result[\"label\"], result[\"score\"]\n",
    "\n",
    "# Apply sentiment analysis to the dataset\n",
    "df[\"sentiment\"] = df[\"cleaned_text\"].apply(lambda x: analyze_sentiment(x)[0])\n",
    "df[\"sentiment_score\"] = df[\"cleaned_text\"].apply(lambda x: analyze_sentiment(x)[1])\n",
    "print(df[[\"text\", \"sentiment\", \"sentiment_score\"]].head())"
   ],
   "id": "67d55c1effe8624a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Visualization",
   "id": "b2d500d5b21f9e64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot issue categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x=\"predicted_category\", order=df[\"predicted_category\"].value_counts().index)\n",
    "plt.title(\"Distribution of Issue Categories\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x=\"sentiment\")\n",
    "plt.title(\"Distribution of Sentiment\")\n",
    "plt.show()"
   ],
   "id": "ffd0963c5eb1012d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exporting Results",
   "id": "a043fac2461f0740"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save results to CSV\n",
    "df.to_csv(\"processed_letters.csv\", index=False)\n",
    "\n",
    "# Save results to JSON\n",
    "df.to_json(\"processed_letters.json\", orient=\"records\")"
   ],
   "id": "c48ee80de6ee4b33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Building an API",
   "id": "e3a234e3a4e9c6fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    text = data[\"text\"]\n",
    "    category = model.predict([text])[0]\n",
    "    sentiment = analyze_sentiment(text)[0]\n",
    "    return jsonify({\"category\": category, \"sentiment\": sentiment})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ],
   "id": "39cd14cba14f770b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
